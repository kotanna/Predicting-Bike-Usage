{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data 802: Analytical Tools and Foundations\n",
    "# Homework assignment 1: Part 1\n",
    "# Last updated: June 14, 2018 by Anna M. Kot\n",
    "\n",
    "# You are also given hourly weather information for DC area for the \n",
    "# last five years. The first objective is to merge all of this information to \n",
    "# create one flat file. You are also required to create a separate holiday/ \n",
    "# adverse event flag variable to be used in predictive modeling\n",
    "\n",
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "\n",
    "# Set the working directory to the folder location containing \n",
    "# the raw Capital Bikeshare trip data and the weather data. \n",
    "# The folder location containing the raw data should contain \n",
    "# Capital Bikeshare trip data for only quarters one through\n",
    "# four for the years 2016 and 2017 (e.g., 2016Q1-capitalbikeshare-tripdata.csv).\n",
    "os.chdir(\"/Users/annakot/Desktop/M.S. Analytics/Data 802/01. HW1/Raw Data\")\n",
    "\n",
    "# Import the eight raw Capital Bikeshare data files into \n",
    "# a single data frame named CBSdf.\n",
    "CBSdf = pd.DataFrame([])\n",
    " \n",
    "for counter, file in enumerate(glob.glob(\"201*\")):\n",
    "    namedf = pd.read_csv(file, skiprows=0, usecols=range(9))\n",
    "    CBSdf = CBSdf.append(namedf)\n",
    "\n",
    "# Import the raw weather data into a single data frame named Wdf.\n",
    "Wdf = pd.DataFrame([])\n",
    " \n",
    "for counter, file in enumerate(glob.glob(\"W*\")):\n",
    "    namedf = pd.read_csv(file, skiprows=0, usecols=range(28))\n",
    "    Wdf = Wdf.append(namedf)\n",
    "    \n",
    "# Create an array, CBSdfArray, to segment year, month, date, \n",
    "# and hour from CBSdf and append to CBSdfArray.\n",
    "CBSdfArray = np.array(CBSdf[\"Start date\"])\n",
    "year=[]\n",
    "month=[]\n",
    "date=[]\n",
    "hour=[]\n",
    "\n",
    "for i in CBSdfArray:\n",
    "    j = datetime.datetime.strptime(i, \"%Y-%m-%d %H:%M:%S\")\n",
    "    year.append(j.year)\n",
    "    month.append(str(j.month).zfill(2))\n",
    "    date.append(str(j.day).zfill(2))\n",
    "    hour.append(str(j.hour).zfill(2))\n",
    "    \n",
    "# Create a new Year, Month, Day, and Hour column, respectively, in \n",
    "# CBSdf and append segmented year, month, date, and hour from CBSdfArray.    \n",
    "CBSdf[\"Year\"] = year\n",
    "CBSdf[\"Month\"] = month\n",
    "CBSdf[\"Day\"] = date\n",
    "CBSdf[\"Hour\"] = hour\n",
    "\n",
    "# Create a new column in CBSdf called Date_Key, concatenating \n",
    "# Year, Month, Day, and Hour columns from CBSdf.\n",
    "CBSdf[\"Date_Key\"] = CBSdf[\"Year\"].astype(str)+\"-\"+CBSdf[\"Month\"].astype(str)+\"-\"+CBSdf[\"Day\"].astype(str)+\"-\"+CBSdf[\"Hour\"].astype(str)\n",
    "\n",
    "# Create an array, WdfArray, to segment year, month, date, \n",
    "# and hour from Wdf and append to WdfArray.\n",
    "WdfArray = np.array(Wdf[\"dt_iso\"])\n",
    "year=[]\n",
    "month=[]\n",
    "date=[]\n",
    "hour=[]\n",
    "\n",
    "for i in WdfArray:\n",
    "    j = datetime.datetime.strptime(i, \"%Y-%m-%d %H:%M:%S +0000 UTC\")\n",
    "    year.append(j.year)\n",
    "    month.append(str(j.month).zfill(2))\n",
    "    date.append(str(j.day).zfill(2))\n",
    "    hour.append(str(j.hour).zfill(2))\n",
    "    \n",
    "# Create a new Year, Month, Day, and Hour column, respectively, in \n",
    "# Wdf and append segmented year, month, date, and hour from WdfArray. \n",
    "Wdf[\"Year\"] = year\n",
    "Wdf[\"Month\"] = month\n",
    "Wdf[\"Day\"] = date\n",
    "Wdf[\"Hour\"] = hour\n",
    "\n",
    "# Create a new column in Wdf called Date_Key, concatenating \n",
    "# Year, Month, Day, and Hour columns from Wdf.\n",
    "Wdf[\"Date_Key\"] = Wdf[\"Year\"].astype(str)+\"-\"+Wdf[\"Month\"].astype(str)+\"-\"+Wdf[\"Day\"].astype(str)+\"-\"+Wdf[\"Hour\"].astype(str)\n",
    "\n",
    "# Create a dataframe, CBSdf_Grouped, illustrating the number \n",
    "# of bikes rented per hour, per station.\n",
    "CBSdf_Grouped = pd.DataFrame (\n",
    "      CBSdf.groupby([\"Date_Key\",\"Start station number\"], sort=True)\n",
    "        .size()\n",
    "        .unstack(fill_value=0)\n",
    "        .reset_index()\n",
    "        .rename_axis(None, axis=1)\n",
    "      )\n",
    "\n",
    "# Create a dataframe, CBSdf_Counts, illustrating the total \n",
    "# number of bikes rented per hour.\n",
    "CBSdf_Counts = pd.DataFrame (\n",
    "      CBSdf.groupby([\"Date_Key\"], sort=True)[\"Start station number\"].count()\n",
    "      )\n",
    "\n",
    "# Merge CBSdf_Counts into CBSdf_Grouped and rename the \n",
    "# 'Start station number' column to 'Total'.\n",
    "CBSdf_Grouped = pd.merge(left=CBSdf_Grouped, right=CBSdf_Counts, left_on=[\"Date_Key\"], how='left', right_index=True)\n",
    "CBSdf_Grouped = CBSdf_Grouped.rename(columns={\"Start station number\": \"Total\"})\n",
    "\n",
    "# Merge Wdf into CBSdf_Grouped to creat a new dataframe, CBSWdf, reflecting one dataframe.\n",
    "CBSWdf = pd.merge(left=CBSdf_Grouped, right=Wdf, on=[\"Date_Key\"], how='left')\n",
    "\n",
    "# Convert temperature data from Kelvin to Fahrenheit.\n",
    "CBSWdf[\"Temp_F\"] = (9/5)*(CBSWdf['temp'] - 273) + 32\n",
    "CBSWdf[\"Temp_min_F\"] = (9/5)*(CBSWdf['temp_min'] - 273) + 32\n",
    "CBSWdf[\"Temp_max_F\"] = (9/5)*(CBSWdf['temp_max'] - 273) + 32\n",
    "\n",
    "# Convert wind speed data from meters/second to miles/hour.\n",
    "CBSWdf[\"Wind_speed_miles\"] = CBSWdf[\"wind_speed\"] * 2.2369\n",
    "\n",
    "# Determine which dates are considered Federal US Holidays and return 'True' or 'False'\n",
    "# in a new column if or if not a Federal US Holiday, respectively.\n",
    "dr = pd.to_datetime(CBSWdf[\"Date_Key\"])\n",
    "cal = calendar()\n",
    "holidays = cal.holidays(start=dr.min(), end=dr.max())\n",
    "\n",
    "CBSWdf['Is_Holiday'] = pd.to_datetime(CBSWdf[\"Date_Key\"]).dt.date.astype('datetime64[ns]').isin(holidays)\n",
    "\n",
    "# Drop unncessary columns\n",
    "CBSWdf.drop(['dt', 'dt_iso', 'city_id','city_name','lat','lon','temp','temp_min','temp_max','sea_level','grnd_level','wind_speed','rain_1h','rain_3h','rain_24h','rain_today','snow_1h','snow_3h','snow_24h','snow_today','weather_icon'], axis=1, inplace=True)\n",
    "\n",
    "# Export the CBSWdf dataframe to a specific folder location \n",
    "# and save as CapitalBikeShareWeather.csv.\n",
    "CBSWdf.to_csv('/Users/annakot/Desktop/M.S. Analytics/Data 802/01. HW1/Raw Data/CapitalBikeShareWeather.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
